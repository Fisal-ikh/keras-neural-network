{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 1.4829 - accuracy: 0.6231 - val_loss: 0.7584 - val_accuracy: 0.8286\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 13s 273us/step - loss: 0.6049 - accuracy: 0.8464 - val_loss: 0.4550 - val_accuracy: 0.8852\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 13s 272us/step - loss: 0.4398 - accuracy: 0.8801 - val_loss: 0.3710 - val_accuracy: 0.9019\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 12s 259us/step - loss: 0.3767 - accuracy: 0.8952 - val_loss: 0.3322 - val_accuracy: 0.9082\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 13s 271us/step - loss: 0.3415 - accuracy: 0.9025 - val_loss: 0.3055 - val_accuracy: 0.9147\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 14s 285us/step - loss: 0.3175 - accuracy: 0.9086 - val_loss: 0.2880 - val_accuracy: 0.9182\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 15s 310us/step - loss: 0.2989 - accuracy: 0.9137 - val_loss: 0.2727 - val_accuracy: 0.9224\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 15s 320us/step - loss: 0.2839 - accuracy: 0.9180 - val_loss: 0.2608 - val_accuracy: 0.9266\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 16s 335us/step - loss: 0.2714 - accuracy: 0.9217 - val_loss: 0.2505 - val_accuracy: 0.9298\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 14s 284us/step - loss: 0.2602 - accuracy: 0.9252 - val_loss: 0.2430 - val_accuracy: 0.9308\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 15s 309us/step - loss: 0.2501 - accuracy: 0.9285 - val_loss: 0.2341 - val_accuracy: 0.9335\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 14s 290us/step - loss: 0.2409 - accuracy: 0.9301 - val_loss: 0.2271 - val_accuracy: 0.9352\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 14s 291us/step - loss: 0.2325 - accuracy: 0.9334 - val_loss: 0.2227 - val_accuracy: 0.9367\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 15s 308us/step - loss: 0.2253 - accuracy: 0.9353 - val_loss: 0.2147 - val_accuracy: 0.9396\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 14s 298us/step - loss: 0.2181 - accuracy: 0.9375 - val_loss: 0.2082 - val_accuracy: 0.9411\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 16s 332us/step - loss: 0.2116 - accuracy: 0.9394 - val_loss: 0.2030 - val_accuracy: 0.9431\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 13s 263us/step - loss: 0.2055 - accuracy: 0.9414 - val_loss: 0.1981 - val_accuracy: 0.9445\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1996 - accuracy: 0.9430 - val_loss: 0.1932 - val_accuracy: 0.9458\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.1941 - accuracy: 0.9432 - val_loss: 0.1894 - val_accuracy: 0.9467\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1890 - accuracy: 0.9456 - val_loss: 0.1849 - val_accuracy: 0.9498\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "Test score: 0.18599770209044217\n",
      "Test accuracy: 0.9463000297546387\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(1671)\n",
    "\n",
    "# Network parameters\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10  # number of outputs = number of digits\n",
    "OPTIMIZER = SGD()  # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2  # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# Load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "RESHAPED = 784\n",
    "\n",
    "# Reshape and normalize data\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "# Evaluate on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.1839 - accuracy: 0.9475 - val_loss: 0.1818 - val_accuracy: 0.9502\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.1791 - accuracy: 0.9486 - val_loss: 0.1771 - val_accuracy: 0.9509\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.1747 - accuracy: 0.9502 - val_loss: 0.1742 - val_accuracy: 0.9511\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.1702 - accuracy: 0.9509 - val_loss: 0.1705 - val_accuracy: 0.9528\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.1661 - accuracy: 0.9525 - val_loss: 0.1678 - val_accuracy: 0.9531\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.1622 - accuracy: 0.9532 - val_loss: 0.1637 - val_accuracy: 0.9542\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.1583 - accuracy: 0.9545 - val_loss: 0.1613 - val_accuracy: 0.9546\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 4s 79us/step - loss: 0.1546 - accuracy: 0.9557 - val_loss: 0.1583 - val_accuracy: 0.9553\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.1510 - accuracy: 0.9569 - val_loss: 0.1560 - val_accuracy: 0.9557\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.1478 - accuracy: 0.9581 - val_loss: 0.1526 - val_accuracy: 0.9571\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "Test score with 10 epochs: 0.15332013074830175\n",
      "Test accuracy with 10 epochs: 0.9535999894142151\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Varying Number of Epochs\n",
    "NB_EPOCH = 10  # Reduce epochs\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score with 10 epochs:\", score[0])\n",
    "print('Test accuracy with 10 epochs:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 7s 142us/step - loss: 0.1446 - accuracy: 0.9581 - val_loss: 0.1502 - val_accuracy: 0.9578\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 0.1388 - accuracy: 0.9601 - val_loss: 0.1440 - val_accuracy: 0.9593\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 10s 219us/step - loss: 0.1330 - accuracy: 0.9625 - val_loss: 0.1416 - val_accuracy: 0.9598\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 26s 533us/step - loss: 0.1275 - accuracy: 0.9638 - val_loss: 0.1371 - val_accuracy: 0.9619\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 14s 301us/step - loss: 0.1226 - accuracy: 0.9654 - val_loss: 0.1333 - val_accuracy: 0.9619\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 16s 341us/step - loss: 0.1181 - accuracy: 0.9669 - val_loss: 0.1304 - val_accuracy: 0.9620\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 11s 235us/step - loss: 0.1137 - accuracy: 0.9683 - val_loss: 0.1287 - val_accuracy: 0.9631\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 9s 180us/step - loss: 0.1094 - accuracy: 0.9697 - val_loss: 0.1264 - val_accuracy: 0.9640\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 8s 170us/step - loss: 0.1056 - accuracy: 0.9705 - val_loss: 0.1224 - val_accuracy: 0.9653\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 13s 275us/step - loss: 0.1019 - accuracy: 0.9717 - val_loss: 0.1195 - val_accuracy: 0.9660\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "Test score with batch size 64: 0.11569416758306325\n",
      "Test accuracy with batch size 64: 0.965399980545044\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Changing Batch Size\n",
    "BATCH_SIZE = 64  # Reduce batch size\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score with batch size 64:\", score[0])\n",
    "print('Test accuracy with batch size 64:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Accuracy Rate Changes\n",
    "\n",
    "## Initial Setup\n",
    "- **Test Accuracy**: 94.63%%\n",
    "\n",
    "## Experiment 1: Varying Number of Epochs\n",
    "- **Test Accuracy**: 95.36%\n",
    "- **Changes**: Reducing the number of epochs from 20 to 10 resulted in a slight decrease in test accuracy. Fewer epochs mean less training time, potentially leading to underfitting as the model may not have fully learned from the data.\n",
    "\n",
    "## Experiment 2: Changing Batch Size\n",
    "- **Test Accuracy**: 96.54%\n",
    "- **Changes**: Reducing the batch size from 128 to 64 resulted in a noticeable change in test accuracy. Smaller batch sizes often lead to more frequent updates to the model weights, which can result in faster convergence but also increased noise, impacting overall accuracy.\n",
    "\n",
    "### Conclusion\n",
    "- Adjusting these parameters showcases their impact on the model's performance. Finding optimal values requires balancing between training time, model convergence, and accuracy on validation and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
